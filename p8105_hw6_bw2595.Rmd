---
title: "p8105_hw6_bw2595"
author: "Blair Wigsten"
date: "11/19/2019"
output: github_document
---
# Problem 1

```{r}
library(tidyverse)
library(purrr)
library(modelr)
library(mgcv)
```

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. 

```{r}
birth = read_csv(file = "data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(babysex = factor(babysex, c("1", "2")), 
         frace = factor(frace, c("1", "2", "3", "4", "8", "9")),
         malform = factor(malform, c("0", "1")), 
         mrace = factor(mrace, c("1", "2", "3", "4", "8"))
         ) %>%
  drop_na()
birth

fit = lm(bwt ~ babysex + gaweeks + malform + smoken, data = birth)

plot = birth %>%
  add_predictions(fit) %>%
  add_residuals(fit) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point()
plot
```
First, the birthweight dataset was loaded and cleaned. All variables were initially in numeric form. Categorical variables, based on variable definitions in the code book, were converted to factor variables. Using drop_na, it was concluded that there were no missing values in the dataset. To create the baseline regression model, I used a hypothetical framework and prior knowledge of factors that would affect birthweight. Our first model includes baby sex, gestational age in weeks, presence or absence of malformations that could affect birthweight, and average number of cigarettes smoked per day during pregnancy. These factors were chosen based on outside knowledge of variables that may influence birthweight. 

** describe the plot **

Compare your model to two others:

One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

```{r}
fit = lm(bwt ~ babysex + gaweeks + malform + smoken, data = birth)

main_effects = lm(bwt ~ blength + gaweeks, data = birth)

interaction = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birth)

```

```{r}
cv_df =
  crossv_mc(birth, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```


```{r}
cv_df = 
  cv_df %>% 
  mutate(fit  = map(train, ~lm(bwt ~ babysex + gaweeks + malform + smoken, data = .x)),
         main_effects = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         interaction  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_fit = map2_dbl(fit, test, ~rmse(model = .x, data = .y)),
         rmse_main    = map2_dbl(main_effects, test, ~rmse(model = .x, data = .y)),
         rmse_interaction = map2_dbl(interaction, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Based on this violin plot, I would conclude that the model including all interactions between the predictors is the best model. This has the lowest rmse, which means that the model with interaction terms has the lowest prediction error. This should be futher validated using hypothesis testing and more concrete measures of cross validation. 

# Problem 2

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
weather_df
```

## Plot of log(beta0*beta1)

```{r}
weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)), 
         results = map(models, broom::tidy)) %>%
  select(results) %>%
  unnest(results) %>%
  select(term, estimate) %>%
  pivot_wider(
    names_from = "term", 
    values_from = "estimate") %>%
  unnest() %>%
  janitor::clean_names() %>%
  mutate(beta0_beta1 = intercept * tmin, 
         log_beta0_beta1 = log(beta0_beta1)) %>%
  ggplot(aes(x = log_beta0_beta1)) +
  geom_density() +
  labs(
    title = "Distribution of Log(beta0*beta1)", 
    x = "log(beta0*beta1)", 
    y = "Density")
```

## Plot of r squared

```{r}
weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)), 
         results = map(models, broom::glance)) %>%
  select(results) %>%
  unnest(results) %>%
  quantile(pull(r_squared, probs=c(0.025, 0.975), na.rm=TRUE)) %>%
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    title = "Distribution of r squared", 
    x = "r squared", 
    y = "Density")
```


The boostrap is helpful when you’d like to perform inference for a parameter / value / summary that doesn’t have an easy-to-write-down distribution in the usual repeated sampling framework. We’ll focus on a simple linear regression with tmax as the response and tmin as the predictor, and are interested in the distribution of two quantities estimated from these data:

r̂ 2
log(β̂ 0∗β̂ 1)

Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. Plot the distribution of your estimates, and describe these in words. Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1). Note: broom::glance() is helpful for extracting r̂ 2 from a fitted regression, and broom::tidy() (with some additional wrangling) should help in computing log(β̂ 0∗β̂ 1).










