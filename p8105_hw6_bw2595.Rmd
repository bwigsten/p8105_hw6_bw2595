---
title: "p8105_hw6_bw2595"
author: "Blair Wigsten"
date: "11/19/2019"
output: github_document
---
# Problem 1

```{r}
library(tidyverse)
library(purrr)
library(modelr)
library(mgcv)
```

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. 

```{r}
birth = read_csv(file = "data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(babysex = factor(babysex, c("1", "2")), 
         frace = factor(frace, c("1", "2", "3", "4", "8", "9")),
         malform = factor(malform, c("0", "1")), 
         mrace = factor(mrace, c("1", "2", "3", "4", "8"))
         ) %>%
  drop_na()
birth

fit = lm(bwt ~ babysex + gaweeks + malform + smoken, data = birth)

plot = birth %>%
  add_predictions(fit) %>%
  add_residuals(fit) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point()
plot
```
First, the birthweight dataset was loaded and cleaned. All variables were initially in numeric form. Categorical variables, based on variable definitions in the code book, were converted to factor variables. Using drop_na, it was concluded that there were no missing values in the dataset. To create the baseline regression model, I used a hypothetical framework and prior knowledge of factors that would affect birthweight. Our first model includes baby sex, gestational age in weeks, presence or absence of malformations that could affect birthweight, and average number of cigarettes smoked per day during pregnancy. These factors were chosen based on outside knowledge of variables that may influence birthweight. 

** describe the plot **

Compare your model to two others:

One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

```{r}
fit = lm(bwt ~ babysex + gaweeks + malform + smoken, data = birth)

main_effects = lm(bwt ~ blength + gaweeks, data = birth)

interaction = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birth)

```

```{r}
cv_df =
  crossv_mc(birth, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```


```{r}
cv_df = 
  cv_df %>% 
  mutate(fit  = map(train, ~lm(bwt ~ babysex + gaweeks + malform + smoken, data = .x)),
         main_effects = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         interaction  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_fit = map2_dbl(fit, test, ~rmse(model = .x, data = .y)),
         rmse_main    = map2_dbl(main_effects, test, ~rmse(model = .x, data = .y)),
         rmse_interaction = map2_dbl(interaction, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Based on this violin plot, I would conclude that the model including all interactions between the predictors is the best model. This has the lowest rmse, which means that the model with interaction terms has the lowest prediction error. This should be futher validated using hypothesis testing and more concrete measures of cross validation. 

# Problem 2

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
weather_df
```

## Plot of log(beta0*beta1)

```{r}
weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)), 
         results = map(models, broom::tidy)) %>%
  select(results) %>%
  unnest(results) %>%
  select(term, estimate) %>%
  pivot_wider(
    names_from = "term", 
    values_from = "estimate") %>%
  unnest() %>%
  janitor::clean_names() %>%
  mutate(beta0_beta1 = intercept * tmin, 
         log_beta0_beta1 = log(beta0_beta1)) %>%
  ggplot(aes(x = log_beta0_beta1)) +
  geom_density() +
  labs(
    title = "Distribution of Log(beta0*beta1)", 
    x = "log(beta0*beta1)", 
    y = "Density")
```

* This plot shows the density of log(beta0*beta1) values of our 5000 bootstrap samples. The distribution looks relatively normal. The highest density of log(beta0*beta1) is around 2.02. We are 95% confident that the true value of log(beta0*beta1) lies between 1.965 and 2.058, produced from the code chunk below. 

```{r}
CI = weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)), 
         results = map(models, broom::tidy)) %>%
  select(results) %>%
  unnest(results) %>%
  select(term, estimate) %>%
  pivot_wider(
    names_from = "term", 
    values_from = "estimate") %>%
  unnest() %>%
  janitor::clean_names() %>%
  mutate(beta0_beta1 = intercept * tmin, 
         log_beta0_beta1 = log(beta0_beta1)) %>%
  pull(log_beta0_beta1) %>%
  as.vector() %>%
  quantile(probs = c(0.025, 0.975), na.rm = TRUE) 
CI
```


## Plot of r squared

```{r}
weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)), 
         results = map(models, broom::glance)) %>%
  select(results) %>%
  unnest(results) %>%
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    title = "Distribution of r squared", 
    x = "r squared", 
    y = "Density")
```
* This plot shows the distribution of r-squared for the 5000 bootstrap samples. The highest density of r-squared values is around 0.913, with a density of around 47. Given this r-squared value, more times than not, the linear model containing only tmin explains about 91.3% of the variation in tmax. Since we are looking for our model to have a high r-squared value and the density is often between 0.89 and 0.93, our model is pretty good at explaining variation in tmax. Taking the 95% confidence interval into consideration of 0.894 to 0.928 shown below, we are 95% confident that the true r-squared value lies between these two numbers, which is a relatively high r-squared value (which is what we want).

```{r}
CI = weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)), 
         results = map(models, broom::glance)) %>%
  select(results) %>%
  unnest(results) %>%
  pull(r.squared) %>%
  as.vector() %>%
  quantile(probs = c(0.025, 0.975), na.rm = TRUE)
CI
```







